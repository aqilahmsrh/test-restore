name: Testing Workflow

on:

  workflow_dispatch:
    inputs:
      # version:
      #   description: 'Repo Tag Name (Ex.: yyyymmdd-hhmmss)'
      #   type: string
      #   required: true
      environment:
        description: 'test'
        type: string
        required: true

jobs:

  DEXSIT-backup:
    if: inputs.environment == 'test'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.7

      - name: Create Test Database Dump
        env:
          SIT_DB_USER: ${{ secrets.DB_USER }}
          SIT_DB_PASSWORD: ${{ secrets.DB_PASSWORD }} 
          SIT_DB_HOST: ${{ secrets.DB_HOST }} 
          SIT_DB_NAME: ${{ secrets.DB_NAME }}
        run: |
          TIMESTAMP=$(date +"%Y%m%d%H%M%S")
          SIT_LOCAL_DUMP_FILE="dump-127.0.0.1-sit-${TIMESTAMP}.sql"
          mysqldump -h $DB_HOST -u $DB_USER -p$DB_PASSWORD $DB_NAME > $SIT_LOCAL_DUMP_FILE
          echo "SIT_LOCAL_DUMP_FILE=$SIT_LOCAL_DUMP_FILE" >> $GITHUB_ENV

      - name: Create Backup File Artifacts
        id: 'create_artifacts'
        uses: actions/upload-artifact@v3
        with:
          name: ${{ env.SIT_LOCAL_DUMP_FILE }}
          path: ${{ env.SIT_LOCAL_DUMP_FILE }}

      - name: Upload Backup to S3
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.DEVOPS_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.DEVOPS_AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          SIT_BUCKET_NAME: ${{ secrets.DEVOPS_S3_BUCKET }}
        run: |
          aws s3 cp ${{ env.SIT_LOCAL_DUMP_FILE }} $SIT_BUCKET_NAME
          S3_URI="$SIT_BUCKET_NAME/${{ env.SIT_LOCAL_DUMP_FILE }}"
          echo "S3_URI=$S3_URI" >> $GITHUB_ENV
          echo "Uploaded backup to S3: $S3_URI"
          
      - name: Install dependencies
        env:
          SENDER_EMAIL: ${{ secrets.SENDER_EMAIL }}
          RECEIVER_EMAIL: ${{ secrets.RECEIVER_EMAIL }}
          PASSWORD_EMAIL: ${{ secrets.PASSWORD_EMAIL }}
        run: |
          python -m pip install --upgrade pip
          pip install pipenv 
          pipenv install
          pwd
          pipenv run python src/send-email.py
      
      # - name: Upload to AWS S3
      #   env:
      #     AWS_ACCESS_KEY_ID: ${{ secrets.DEVOPS_AWS_ACCESS_KEY_ID }}
      #     AWS_SECRET_ACCESS_KEY: ${{ secrets.DEVOPS_AWS_SECRET_ACCESS_KEY }}
      #     AWS_REGION: ${{ secrets.AWS_REGION }}
      #     BUCKET_NAME: s3://bucket-test-777/backup-db/
      #   run: |
      #     aws s3 cp test.txt $BUCKET_NAME
      #     echo "S3 URI: $BUCKET_NAME/test.txt"

      # - name: Send email
      #   uses: dawidd6/action-send-mail@v3
      #   with:
      #     server_address: smtp.gmail.com
      #     server_port: 465
      #     password: ${{ secrets.PASSWORD_EMAIL }}
      #     subject: Testing
      #     body: testing 123
      #     to: ${{ secrets.RECEIVER_EMAIL }}
      #     from: ${{ secrets.SENDER_EMAIL }}
          
      # - name: Generate S3 Object URL
      #   id: s3
      #   env:
      #     AWS_ACCESS_KEY_ID: ${{ secrets.DEVOPS_AWS_ACCESS_KEY_ID }}
      #     AWS_SECRET_ACCESS_KEY: ${{ secrets.DEVOPS_AWS_SECRET_ACCESS_KEY }}
      #     AWS_REGION: ${{ secrets.AWS_REGION }}
      #   run: |
      #     aws s3 presign s3://bucket-test-777/backup-db/test.txt
      #     # DOWNLOAD_URL=$(aws s3 presign s3://bucket-test-777/backup-db/test.txt --expires-in 3600 --region ap-southeast-1)
      #     # echo "DOWNLOAD_URL=$DOWNLOAD_URL" >> $GITHUB_ENV
      #     # echo "This is the link: $DOWNLOAD_URL"

      # - name: Echo S3 Object URL
      #   run: |
      #     echo "Download link for the uploaded object: $DOWNLOAD_URL"
