name: Testing Workflow

on:

  workflow_dispatch:
    inputs:
      # version:
      #   description: 'Repo Tag Name (Ex.: yyyymmdd-hhmmss)'
      #   type: string
      #   required: true
      # environment:
      #   description: 'uat/sit'
      #   type: string
      #   required: true
      name:
        description: 'short name'
        type: string
        required: true
      email:
        description: 'example@regovtech.com'
        type: string
        required: true
      
jobs:

  Send-Email-Devops:
    # if: inputs.environment == 'test'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Print Triggered Workflow Link
        run: |
          WORKFLOW_LINK="https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          echo "WORKFLOW_LINK=$WORKFLOW_LINK" >> $GITHUB_ENV
          echo "your $WORKFLOW_LINK"
          
      - name: Send Triggered Notification to DevOps
        env:
          SENDER_EMAIL: ${{ secrets.SENDER_EMAIL }}
          RECEIVER_EMAIL: ${{ github.event.inputs.email }}
          REQUESTED_USER: ${{ github.event.inputs.name }}
          PASSWORD_EMAIL: ${{ secrets.PASSWORD_EMAIL }}
        run: |
          python -m pip install --upgrade pip
          pip install pipenv 
          pipenv install
          pwd
          pipenv run python src/send-email.py
      
  Backup-MySQL-Database:
    # if: inputs.environment == 'test'
    runs-on: ubuntu-latest
    environment:
       name: try
       
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Upload to AWS S3
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.DEVOPS_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.DEVOPS_AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          BUCKET_NAME: ${{ secrets.DEVOPS_S3_BUCKET }}
        run: |
            TIMESTAMP=$(date +"%Y%m%d%H%M%S")
            SIT_LOCAL_DUMP_FILE="dump-127.0.0.1-sit-${TIMESTAMP}.sql"
            mv test.txt $SIT_LOCAL_DUMP_FILE
            aws s3 cp $SIT_LOCAL_DUMP_FILE $BUCKET_NAME
            S3_URI="$BUCKET_NAME${{ env.SIT_LOCAL_DUMP_FILE }}"
            echo "S3_URI=$S3_URI" >> $GITHUB_ENV
            echo "Uploaded backup to S3: $S3_URI"

      # - name: Create Test Database Dump
      #   env:
      #     DB_USER: ${{ secrets.DB_USER }}
      #     DB_PASSWORD: ${{ secrets.DB_PASSWORD }} 
      #     DB_HOST: ${{ secrets.DB_HOST }} 
      #     DB_NAME: ${{ secrets.DB_NAME }}
      #   run: |
      #     TIMESTAMP=$(date +"%Y%m%d%H%M%S")
      #     SIT_LOCAL_DUMP_FILE="dump-127.0.0.1-sit-${TIMESTAMP}.sql"
      #     mysqldump -h $DB_HOST -u $DB_USER -p$DB_PASSWORD $DB_NAME > $SIT_LOCAL_DUMP_FILE
      #     echo "SIT_LOCAL_DUMP_FILE=$SIT_LOCAL_DUMP_FILE" >> $GITHUB_ENV

      # - name: Create Backup File Artifacts
      #   id: 'create_artifacts'
      #   uses: actions/upload-artifact@v3
      #   with:
      #     name: ${{ env.SIT_LOCAL_DUMP_FILE }}
      #     path: ${{ env.SIT_LOCAL_DUMP_FILE }}

      # - name: Upload Backup to S3
      #   env:
      #     AWS_ACCESS_KEY_ID: ${{ secrets.DEVOPS_AWS_ACCESS_KEY_ID }}
      #     AWS_SECRET_ACCESS_KEY: ${{ secrets.DEVOPS_AWS_SECRET_ACCESS_KEY }}
      #     AWS_REGION: ${{ secrets.AWS_REGION }}
      #     SIT_BUCKET_NAME: ${{ secrets.DEVOPS_S3_BUCKET }}
      #   run: |
      #     aws s3 cp ${{ env.SIT_LOCAL_DUMP_FILE }} $SIT_BUCKET_NAME
      #     S3_URI="$SIT_BUCKET_NAME${{ env.SIT_LOCAL_DUMP_FILE }}"
      #     echo "S3_URI=$S3_URI" >> $GITHUB_ENV
      #     echo "Uploaded backup to S3: $S3_URI"
          
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.7
          
      - name: Send Email S3
        env:
          SENDER_EMAIL: ${{ secrets.SENDER_EMAIL }}
          RECEIVER_EMAIL: ${{ github.event.inputs.email }}
          PASSWORD_EMAIL: ${{ secrets.PASSWORD_EMAIL }}
          S3_URI: ${{ env.S3_URI }}
        run: |
          python -m pip install --upgrade pip
          pip install pipenv 
          pipenv install
          pwd
          pipenv run python src/send-bucket.py
      
      # - name: Upload to AWS S3
      #   env:
      #     AWS_ACCESS_KEY_ID: ${{ secrets.DEVOPS_AWS_ACCESS_KEY_ID }}
      #     AWS_SECRET_ACCESS_KEY: ${{ secrets.DEVOPS_AWS_SECRET_ACCESS_KEY }}
      #     AWS_REGION: ${{ secrets.AWS_REGION }}
      #     BUCKET_NAME: s3://bucket-test-777/backup-db/
      #   run: |
      #       TIMESTAMP=$(date +"%Y%m%d%H%M%S")
      #       SIT_LOCAL_DUMP_FILE="dump-127.0.0.1-sit-${TIMESTAMP}.sql"
      #       mv test.txt $SIT_LOCAL_DUMP_FILE
      #       aws s3 cp $SIT_LOCAL_DUMP_FILE $BUCKET_NAME
      #       echo "S3 URI: $BUCKET_NAME$SIT_LOCAL_DUMP_FILE"

      # - name: Send email
      #   uses: dawidd6/action-send-mail@v3
      #   with:
      #     server_address: smtp.gmail.com
      #     server_port: 465
      #     password: ${{ secrets.PASSWORD_EMAIL }}
      #     subject: Testing
      #     body: testing 123
      #     to: ${{ secrets.RECEIVER_EMAIL }}
      #     from: ${{ secrets.SENDER_EMAIL }}
          
      # - name: Generate S3 Object URL
      #   id: s3
      #   env:
      #     AWS_ACCESS_KEY_ID: ${{ secrets.DEVOPS_AWS_ACCESS_KEY_ID }}
      #     AWS_SECRET_ACCESS_KEY: ${{ secrets.DEVOPS_AWS_SECRET_ACCESS_KEY }}
      #     AWS_REGION: ${{ secrets.AWS_REGION }}
      #   run: |
      #     aws s3 presign s3://bucket-test-777/backup-db/test.txt
      #     # DOWNLOAD_URL=$(aws s3 presign s3://bucket-test-777/backup-db/test.txt --expires-in 3600 --region ap-southeast-1)
      #     # echo "DOWNLOAD_URL=$DOWNLOAD_URL" >> $GITHUB_ENV
      #     # echo "This is the link: $DOWNLOAD_URL"

      # - name: Echo S3 Object URL
      #   run: |
      #     echo "Download link for the uploaded object: $DOWNLOAD_URL"
